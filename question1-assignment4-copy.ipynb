{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9922717,"sourceType":"datasetVersion","datasetId":6098554},{"sourceId":9922856,"sourceType":"datasetVersion","datasetId":6098661}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:00:29.341236Z","iopub.execute_input":"2024-11-16T10:00:29.341766Z","iopub.status.idle":"2024-11-16T10:00:29.348246Z","shell.execute_reply.started":"2024-11-16T10:00:29.341707Z","shell.execute_reply":"2024-11-16T10:00:29.347043Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"print(\"Hello\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:00:29.350855Z","iopub.execute_input":"2024-11-16T10:00:29.351213Z","iopub.status.idle":"2024-11-16T10:00:29.362128Z","shell.execute_reply.started":"2024-11-16T10:00:29.351172Z","shell.execute_reply":"2024-11-16T10:00:29.361031Z"}},"outputs":[{"name":"stdout","text":"Hello\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# importing libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport torchvision\nfrom torchvision import datasets, transforms\nfrom torchvision import models\nimport os\nimport time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:00:29.363980Z","iopub.execute_input":"2024-11-16T10:00:29.364335Z","iopub.status.idle":"2024-11-16T10:00:33.698359Z","shell.execute_reply.started":"2024-11-16T10:00:29.364294Z","shell.execute_reply":"2024-11-16T10:00:33.697368Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Building data loaders","metadata":{}},{"cell_type":"code","source":"dataset_dir = '/kaggle/input/img-dataset-q1/images'  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:00:33.700123Z","iopub.execute_input":"2024-11-16T10:00:33.700530Z","iopub.status.idle":"2024-11-16T10:00:33.704418Z","shell.execute_reply.started":"2024-11-16T10:00:33.700496Z","shell.execute_reply":"2024-11-16T10:00:33.703500Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n])\n\ntrain_dir = os.path.join(dataset_dir, 'resized_train')\ntest_dir = os.path.join(dataset_dir, 'resized_test')\n\n# Load the training and testing datasets using ImageFolder\ntrain_data = datasets.ImageFolder(train_dir, transform=transform)\ntest_data = datasets.ImageFolder(test_dir, transform=transform)\n\n# Create DataLoader instances for training and testing\ntrain_loader = DataLoader(train_data, batch_size=12, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=8, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:00:33.705746Z","iopub.execute_input":"2024-11-16T10:00:33.706523Z","iopub.status.idle":"2024-11-16T10:00:33.775364Z","shell.execute_reply.started":"2024-11-16T10:00:33.706479Z","shell.execute_reply":"2024-11-16T10:00:33.774610Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# 1 block VGG","metadata":{}},{"cell_type":"code","source":"class SimpleVGGBlock(nn.Module):\n    def __init__(self):\n        super(SimpleVGGBlock, self).__init__()\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n        self.fc1 = nn.Linear(32 * 224 * 224, 2)  # Output layer with 2 units for binary classification\n\n    def forward(self, x):\n        x = torch.relu(self.conv1(x))\n        x = torch.relu(self.conv2(x))\n        x = x.view(x.size(0), -1)  # Flatten the output\n        x = self.fc1(x)  # Output layer with 2 units\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:00:33.777157Z","iopub.execute_input":"2024-11-16T10:00:33.777475Z","iopub.status.idle":"2024-11-16T10:00:33.784220Z","shell.execute_reply.started":"2024-11-16T10:00:33.777424Z","shell.execute_reply":"2024-11-16T10:00:33.783314Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### Model definition","metadata":{}},{"cell_type":"code","source":"model = SimpleVGGBlock()\ncriterion = nn.CrossEntropyLoss()  # Suitable for multi-class classification (binary classification with 2 classes)\noptimizer = optim.Adam(model.parameters(), lr=0.0001)\ntrain_loss = []\ntrain_acc = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:00:33.785562Z","iopub.execute_input":"2024-11-16T10:00:33.786190Z","iopub.status.idle":"2024-11-16T10:00:33.845704Z","shell.execute_reply.started":"2024-11-16T10:00:33.786146Z","shell.execute_reply":"2024-11-16T10:00:33.844929Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### Training and inference","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\n#Training \nnum_epochs = 10\nfor epoch in range(num_epochs):\n    model.train()  # Set the model to training mode\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for inputs, labels in train_loader:\n        optimizer.zero_grad()  \n        outputs = model(inputs)  \n        loss = criterion(outputs, labels)  \n        loss.backward()  \n        optimizer.step()  \n        \n        running_loss += loss.item()  \n        \n        _, predicted = torch.max(outputs, 1) \n        total += labels.size(0) \n        correct += (predicted == labels).sum().item() \n        \n    accuracy = 100 * correct / total\n    train_loss.append(running_loss/len(train_loader))\n    train_acc.append(accuracy)\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%\")\nend_time = time.time()\n\nprint(f'\\nTime taken to train the model is {end_time - start_time}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:00:33.846822Z","iopub.execute_input":"2024-11-16T10:00:33.847133Z","iopub.status.idle":"2024-11-16T10:01:40.763779Z","shell.execute_reply.started":"2024-11-16T10:00:33.847101Z","shell.execute_reply":"2024-11-16T10:01:40.761619Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10], Loss: 8.9676, Accuracy: 58.12%\nEpoch [2/10], Loss: 1.1181, Accuracy: 80.00%\nEpoch [3/10], Loss: 0.8018, Accuracy: 81.25%\nEpoch [4/10], Loss: 0.7652, Accuracy: 84.38%\nEpoch [5/10], Loss: 0.1265, Accuracy: 94.38%\nEpoch [6/10], Loss: 0.0381, Accuracy: 98.75%\nEpoch [7/10], Loss: 0.0080, Accuracy: 100.00%\nEpoch [8/10], Loss: 0.0073, Accuracy: 100.00%\nEpoch [9/10], Loss: 0.0027, Accuracy: 100.00%\nEpoch [10/10], Loss: 0.0018, Accuracy: 100.00%\n\nTime taken to train the model is 66.90767645835876\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"model.eval()  \ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        outputs = model(inputs)  \n        _, predicted = torch.max(outputs, 1) \n        total += labels.size(0)  \n        correct += (predicted == labels).sum().item()  \n\nprint(f\"\\nTraining loss history: {train_loss}\")\nprint(f\"\\nTraining accuracy history: {train_acc}\")\n# Test accuracy\ntest_accuracy = 100 * correct / total\nprint(f\"\\nTest Accuracy: {test_accuracy:.2f}%\")\n\n# Number of model parameters\ntotal_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"\\nNumber of model parameters: {total_params}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:01:40.765799Z","iopub.execute_input":"2024-11-16T10:01:40.766320Z","iopub.status.idle":"2024-11-16T10:01:41.457996Z","shell.execute_reply.started":"2024-11-16T10:01:40.766254Z","shell.execute_reply":"2024-11-16T10:01:41.457155Z"}},"outputs":[{"name":"stdout","text":"\nTraining loss history: [8.967631974390574, 1.1180523135034102, 0.8018220148182341, 0.7651546373318914, 0.12650143319375015, 0.03806039148080994, 0.008049304562778812, 0.007329075855003404, 0.0026956598875195986, 0.0017750315689357063]\n\nTraining accuracy history: [58.125, 80.0, 81.25, 84.375, 94.375, 98.75, 100.0, 100.0, 100.0, 100.0]\n\nTest Accuracy: 70.00%\n\nNumber of model parameters: 3216354\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# 3 block VGG ","metadata":{}},{"cell_type":"code","source":"class VGG3Block(nn.Module):\n    def __init__(self):\n        super(VGG3Block, self).__init__()\n        \n        # 3 convolutional blocks with Conv2d and MaxPool2d\n        self.block1 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),  # Conv1\n            nn.ReLU(),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),  # Conv2\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)  # MaxPool\n        )\n\n        self.block2 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),  # Conv1\n            nn.ReLU(),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),  # Conv2\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)  # MaxPool\n        )\n\n        self.block3 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),  # Conv1\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),  # Conv2\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)  # MaxPool\n        )\n        \n        self.fc1 = nn.Linear(256 * 28 * 28, 512)  \n        self.fc2 = nn.Linear(512, 2)  # Output layer with 2 units (binary classification)\n\n    def forward(self, x):\n        \n        x = self.block1(x)\n        x = self.block2(x)\n        x = self.block3(x)\n        \n        x = x.view(x.size(0), -1)\n        \n        x = torch.relu(self.fc1(x))\n        x = self.fc2(x)  \n        \n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:02:28.046116Z","iopub.execute_input":"2024-11-16T10:02:28.046530Z","iopub.status.idle":"2024-11-16T10:02:28.057164Z","shell.execute_reply.started":"2024-11-16T10:02:28.046471Z","shell.execute_reply":"2024-11-16T10:02:28.056228Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Initialize the model, loss function, and optimizer\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:02:25.852744Z","iopub.execute_input":"2024-11-16T10:02:25.853130Z","iopub.status.idle":"2024-11-16T10:02:25.858734Z","shell.execute_reply.started":"2024-11-16T10:02:25.853093Z","shell.execute_reply":"2024-11-16T10:02:25.857739Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"model_two_3blocks = VGG3Block().to(device)\ncriterion = nn.CrossEntropyLoss() \noptimizer = optim.Adam(model_two_3blocks.parameters(), lr=0.0001)\ntrain_loss = []\ntrain_acc = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:03:02.112897Z","iopub.execute_input":"2024-11-16T10:03:02.113749Z","iopub.status.idle":"2024-11-16T10:03:03.206381Z","shell.execute_reply.started":"2024-11-16T10:03:02.113709Z","shell.execute_reply":"2024-11-16T10:03:03.205494Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"start_time = time.time()\n\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    model_two_3blocks.train() \n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()  \n        outputs = model_two_3blocks(inputs)  \n        loss = criterion(outputs, labels)  \n        loss.backward()  \n        optimizer.step()  \n        \n        running_loss += loss.item() \n        \n        _, predicted = torch.max(outputs, 1)  \n        total += labels.size(0)  \n        correct += (predicted == labels).sum().item()  \n    \n    accuracy = 100 * correct / total\n    train_loss.append(running_loss/len(train_loader))\n    train_acc.append(accuracy)\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%\")\n\nend_time = time.time()\nprint(f'\\nTime taken to train the model_two_3blocks is {end_time - start_time:.2f} seconds')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:04:08.794377Z","iopub.execute_input":"2024-11-16T10:04:08.794760Z","iopub.status.idle":"2024-11-16T10:04:23.068744Z","shell.execute_reply.started":"2024-11-16T10:04:08.794725Z","shell.execute_reply":"2024-11-16T10:04:23.067789Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10], Loss: 0.7019, Accuracy: 51.88%\nEpoch [2/10], Loss: 0.6520, Accuracy: 64.38%\nEpoch [3/10], Loss: 0.5789, Accuracy: 71.88%\nEpoch [4/10], Loss: 0.5168, Accuracy: 70.62%\nEpoch [5/10], Loss: 0.4011, Accuracy: 80.00%\nEpoch [6/10], Loss: 0.3033, Accuracy: 88.75%\nEpoch [7/10], Loss: 0.1879, Accuracy: 93.75%\nEpoch [8/10], Loss: 0.1174, Accuracy: 94.38%\nEpoch [9/10], Loss: 0.1584, Accuracy: 93.12%\nEpoch [10/10], Loss: 0.1953, Accuracy: 89.38%\n\nTime taken to train the model_two_3blocks is 14.27 seconds\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"model_two_3blocks.eval()  # Set the model_two_3blocks to evaluation mode\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model_two_3blocks(inputs)  # Forward pass\n        _, predicted = torch.max(outputs, 1)  # Get predicted class labels\n        total += labels.size(0)  # Update total samples\n        correct += (predicted == labels).sum().item()  \ntest_accuracy = 100 * correct / total\n\ntotal_params = sum(p.numel() for p in model_two_3blocks.parameters() if p.requires_grad)\n\nprint(f\"\\nTraining loss history: \\n{train_loss}\")\nprint(f\"\\nTraining accuracy history:\\n {train_acc}\")\nprint(f\"\\nTest Accuracy: {test_accuracy:.2f}%\")\nprint(f\"\\nNumber of model_two_3blocks parameters: {total_params}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:04:59.332776Z","iopub.execute_input":"2024-11-16T10:04:59.333130Z","iopub.status.idle":"2024-11-16T10:04:59.504878Z","shell.execute_reply.started":"2024-11-16T10:04:59.333097Z","shell.execute_reply":"2024-11-16T10:04:59.503932Z"}},"outputs":[{"name":"stdout","text":"\nTraining loss history: \n[0.7019052675792149, 0.6520498096942902, 0.5789400977747781, 0.516767544405801, 0.4010657998067992, 0.30333614881549564, 0.18785322776862554, 0.11743209644087724, 0.15843702041144883, 0.19533697622162954]\n\nTraining accuracy history:\n [51.875, 64.375, 71.875, 70.625, 80.0, 88.75, 93.75, 94.375, 93.125, 89.375]\n\nTest Accuracy: 65.00%\n\nNumber of model_two_3blocks parameters: 103907394\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# 3 block with image augmentation ","metadata":{}},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),  \n    transforms.RandomRotation(20), \n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # Random color jitter\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # VGG normalization\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # VGG normalization\n])\n\n\ntrain_dir = os.path.join(dataset_dir, 'resized_train')\ntest_dir = os.path.join(dataset_dir, 'resized_test')\n\ntrain_data = datasets.ImageFolder(train_dir, transform=train_transform)\ntest_data = datasets.ImageFolder(test_dir, transform=test_transform)\n\ntrain_loader = DataLoader(train_data, batch_size=8, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=8, shuffle=False)\n\nclass VGGBlock(nn.Module):\n    def __init__(self):\n        super(VGGBlock, self).__init__()\n        \n        # 3 convolutional blocks with Conv2d and MaxPool2d\n        self.block1 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),  # Conv1\n            nn.ReLU(),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),  # Conv2\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)  # MaxPool\n        )\n\n        self.block2 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),  # Conv1\n            nn.ReLU(),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),  # Conv2\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)  # MaxPool\n        )\n\n        self.block3 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),  # Conv1\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),  # Conv2\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)  # MaxPool\n        )\n        \n        # Fully connected layer for binary classification\n        self.fc1 = nn.Linear(256 * 28 * 28, 512)  # Linear layer after flattening the output of the conv layers\n        self.fc2 = nn.Linear(512, 2)  # Output layer with 2 units (binary classification)\n\n    def forward(self, x):\n        # Pass the input through each block\n        x = self.block1(x)\n        x = self.block2(x)\n        x = self.block3(x)\n        \n        # Flatten the output\n        x = x.view(x.size(0), -1)\n        \n        # Fully connected layers\n        x = torch.relu(self.fc1(x))\n        x = self.fc2(x)  # Output layer\n        \n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:06:30.062052Z","iopub.execute_input":"2024-11-16T10:06:30.062771Z","iopub.status.idle":"2024-11-16T10:06:30.085154Z","shell.execute_reply.started":"2024-11-16T10:06:30.062729Z","shell.execute_reply":"2024-11-16T10:06:30.084149Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"model_data_aug = VGGBlock().to(device)  # Move model_data_aug to device (CPU or GPU)\ncriterion = nn.CrossEntropyLoss()  # Suitable for multi-class classification (binary classification with 2 classes)\noptimizer = optim.Adam(model_data_aug.parameters(), lr=0.0001)\n\n# Lists to track loss and accuracy during training\ntrain_loss = []\ntrain_acc = []\n\nstart_time = time.time()\n\n# Training loop\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    model_data_aug.train()  # Set the model_data_aug to training mode\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for i, (inputs, labels) in enumerate(train_loader):\n        # Move data to device (CPU or GPU)\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()  # Zero the gradients\n        \n        # Forward pass\n        outputs = model_data_aug(inputs)  \n        loss = criterion(outputs, labels)  # Compute loss\n        loss.backward()  # Backward pass\n        optimizer.step()  # Update weights\n        \n        running_loss += loss.item()  # Accumulate loss\n        \n        # Get predicted class labels\n        _, predicted = torch.max(outputs, 1)  # Get the index of the max output (class prediction)\n        \n        total += labels.size(0)  # Update total samples\n        correct += (predicted == labels).sum().item()  # Update correct predictions\n        \n        # Print loss and accuracy after every few batches\n        if (i + 1) % 10 == 0:\n            batch_accuracy = 100 * correct / total\n            print(f\"Batch [{i+1}/{len(train_loader)}] Loss: {running_loss / (i+1):.4f}, Accuracy: {batch_accuracy:.2f}%\")\n    \n    # Calculate accuracy for the epoch\n    accuracy = 100 * correct / total\n    train_loss.append(running_loss / len(train_loader))\n    train_acc.append(accuracy)\n    \n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%\")\n\nend_time = time.time()\nprint(f'\\nTime taken to train the model_data_aug: {end_time - start_time} seconds')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:10:26.357638Z","iopub.execute_input":"2024-11-16T10:10:26.358019Z","iopub.status.idle":"2024-11-16T10:10:52.003113Z","shell.execute_reply.started":"2024-11-16T10:10:26.357976Z","shell.execute_reply":"2024-11-16T10:10:52.002153Z"}},"outputs":[{"name":"stdout","text":"Batch [10/20] Loss: 0.7000, Accuracy: 56.25%\nBatch [20/20] Loss: 0.7056, Accuracy: 52.50%\nEpoch [1/10], Loss: 0.7056, Accuracy: 52.50%\nBatch [10/20] Loss: 0.6899, Accuracy: 57.50%\nBatch [20/20] Loss: 0.6981, Accuracy: 50.00%\nEpoch [2/10], Loss: 0.6981, Accuracy: 50.00%\nBatch [10/20] Loss: 0.6948, Accuracy: 47.50%\nBatch [20/20] Loss: 0.6945, Accuracy: 46.88%\nEpoch [3/10], Loss: 0.6945, Accuracy: 46.88%\nBatch [10/20] Loss: 0.6939, Accuracy: 46.25%\nBatch [20/20] Loss: 0.6914, Accuracy: 50.00%\nEpoch [4/10], Loss: 0.6914, Accuracy: 50.00%\nBatch [10/20] Loss: 0.6695, Accuracy: 57.50%\nBatch [20/20] Loss: 0.6822, Accuracy: 55.62%\nEpoch [5/10], Loss: 0.6822, Accuracy: 55.62%\nBatch [10/20] Loss: 0.6995, Accuracy: 50.00%\nBatch [20/20] Loss: 0.6843, Accuracy: 54.38%\nEpoch [6/10], Loss: 0.6843, Accuracy: 54.38%\nBatch [10/20] Loss: 0.6698, Accuracy: 66.25%\nBatch [20/20] Loss: 0.6737, Accuracy: 61.88%\nEpoch [7/10], Loss: 0.6737, Accuracy: 61.88%\nBatch [10/20] Loss: 0.6112, Accuracy: 67.50%\nBatch [20/20] Loss: 0.6441, Accuracy: 65.62%\nEpoch [8/10], Loss: 0.6441, Accuracy: 65.62%\nBatch [10/20] Loss: 0.5543, Accuracy: 72.50%\nBatch [20/20] Loss: 0.5790, Accuracy: 72.50%\nEpoch [9/10], Loss: 0.5790, Accuracy: 72.50%\nBatch [10/20] Loss: 0.6202, Accuracy: 66.25%\nBatch [20/20] Loss: 0.5357, Accuracy: 74.38%\nEpoch [10/10], Loss: 0.5357, Accuracy: 74.38%\n\nTime taken to train the model_data_aug: 24.69383406639099 seconds\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"\nmodel_data_aug.eval()  \ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        # Move data to device (CPU or GPU)\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        outputs = model_data_aug(inputs)  # Forward pass\n        _, predicted = torch.max(outputs, 1)  # Get predicted class labels\n        total += labels.size(0)  # Update total samples\n        correct += (predicted == labels).sum().item()  # Update correct predictions\n\ntest_accuracy = 100 * correct / total\nprint(f\"\\nTest Accuracy: {test_accuracy:.2f}%\")\n\n# Number of model_data_aug parameters\ntotal_params = sum(p.numel() for p in model_data_aug.parameters() if p.requires_grad)\nprint(f\"\\nNumber of model_data_aug parameters: {total_params}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:11:15.722451Z","iopub.execute_input":"2024-11-16T10:11:15.723407Z","iopub.status.idle":"2024-11-16T10:11:15.917923Z","shell.execute_reply.started":"2024-11-16T10:11:15.723363Z","shell.execute_reply":"2024-11-16T10:11:15.916987Z"}},"outputs":[{"name":"stdout","text":"\nTest Accuracy: 72.50%\n\nNumber of model_data_aug parameters: 103907394\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"# testing ai images ","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:15:30.861028Z","iopub.execute_input":"2024-11-16T10:15:30.861666Z","iopub.status.idle":"2024-11-16T10:15:30.865831Z","shell.execute_reply.started":"2024-11-16T10:15:30.861626Z","shell.execute_reply":"2024-11-16T10:15:30.864848Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"folder_path = '/kaggle/input/img-generated-ai'\nlabel_mapping = {\n    \"antelope\": 0,\n    \"rabbit\": 1\n}\n\n# Initialize empty lists for images, labels, and file names\ntest_images = []\ntest_labels = []\nfile_names = []\n\n# Iterate through the files in the folder\nfor file_name in os.listdir(folder_path):\n    if file_name.endswith(('.png', '.jpg', '.jpeg')):  # Ensure it's an image\n        # Load the image\n        image_path = os.path.join(folder_path, file_name)\n        image = Image.open(image_path).convert(\"RGB\")  # Convert to RGB format\n        \n        # Resize the image (optional, standardize to a consistent size, e.g., 224x224)\n        image = image.resize((224, 224))\n        \n        # Convert the image to a numpy array\n        image_array = np.array(image)\n        test_images.append(image_array)\n        \n        # Store the file name\n        file_names.append(file_name)\n        \n        # Determine the label based on the file name\n        if \"antelope\" in file_name.lower():\n            test_labels.append(label_mapping[\"antelope\"])\n        elif \"rabbit\" in file_name.lower():\n            test_labels.append(label_mapping[\"rabbit\"])\n\n# Convert lists to numpy arrays for easy handling\ntest_images = np.array(test_images)\ntest_labels = np.array(test_labels)\n\n# Print out the dataset shape and file names for verification\nprint(f\"Test Images Shape: {test_images.shape}\")\nprint(f\"Test Labels Shape: {test_labels.shape}\")\nprint(f\"File Names: {file_names}\")\nprint(f\"Labels: {test_labels}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:15:32.155808Z","iopub.execute_input":"2024-11-16T10:15:32.156580Z","iopub.status.idle":"2024-11-16T10:15:32.301417Z","shell.execute_reply.started":"2024-11-16T10:15:32.156535Z","shell.execute_reply":"2024-11-16T10:15:32.300517Z"}},"outputs":[{"name":"stdout","text":"Test Images Shape: (4, 224, 224, 3)\nTest Labels Shape: (4,)\nFile Names: ['easy_rabbit.jpg', 'easy_antelope.jpg', 'hard_rabbit.jpg', 'hard_antelope.jpg']\nLabels: [1 0 1 0]\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:15:35.367091Z","iopub.execute_input":"2024-11-16T10:15:35.367505Z","iopub.status.idle":"2024-11-16T10:15:35.372188Z","shell.execute_reply.started":"2024-11-16T10:15:35.367461Z","shell.execute_reply":"2024-11-16T10:15:35.371243Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# Define a custom Dataset class for the test set\nclass CustomTestDataset(Dataset):\n    def __init__(self, images, labels, transform=None):\n        self.images = images\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image = self.images[idx]\n        label = self.labels[idx]\n\n        # Apply transformations if provided\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:15:36.141940Z","iopub.execute_input":"2024-11-16T10:15:36.142306Z","iopub.status.idle":"2024-11-16T10:15:36.148825Z","shell.execute_reply.started":"2024-11-16T10:15:36.142273Z","shell.execute_reply":"2024-11-16T10:15:36.147793Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToTensor(),  # Convert to PyTorch tensor\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize (use your model's normalization parameters)\n])\n\n# Create the test dataset and DataLoader\ntest_dataset_gen = CustomTestDataset(test_images, test_labels, transform=transform)\ntest_loader_gen = DataLoader(test_dataset_gen, batch_size=4, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:18:31.033191Z","iopub.execute_input":"2024-11-16T10:18:31.033572Z","iopub.status.idle":"2024-11-16T10:18:31.039364Z","shell.execute_reply.started":"2024-11-16T10:18:31.033536Z","shell.execute_reply":"2024-11-16T10:18:31.038458Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"def test_fnai(model_gen):    \n    model_gen.eval()  # Set the model to evaluation mode\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model_gen = model_gen.to(device)  # Move model to device\n    \n    # Inference loop\n    all_predictions = []\n    all_labels = []\n    \n    with torch.no_grad():  # No need to compute gradients during inference\n        for images, labels in test_loader_gen:\n            images = images.to(device)  # Move images to the same device as the model\n            labels = labels.to(device)  # Move labels to the same device\n    \n            # Perform inference\n            outputs = model_gen(images)\n            predictions = torch.round(torch.sigmoid(outputs)).squeeze()  # Apply sigmoid and round for binary classification\n    \n            # Store predictions and labels\n            all_predictions.extend(predictions.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    # Print predictions and corresponding ground truth\n    for idx, (pred, label) in enumerate(zip(all_predictions, all_labels)):\n        print(f\"Image {idx + 1}: Predicted: {int(pred)}, Ground Truth: {int(label)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:18:34.463414Z","iopub.execute_input":"2024-11-16T10:18:34.464273Z","iopub.status.idle":"2024-11-16T10:18:34.472279Z","shell.execute_reply.started":"2024-11-16T10:18:34.464232Z","shell.execute_reply":"2024-11-16T10:18:34.471159Z"}},"outputs":[],"execution_count":48}]}